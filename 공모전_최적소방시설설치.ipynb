{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qht2KlnzkrLs"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen \n",
    "from urllib.parse import urlencode, quote_plus\n",
    "import requests\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import wkt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from haversine import haversine\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from pulp import LpProblem, LpMaximize, LpVariable, lpSum, LpBinary, PULP_CBC_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 부르기\n",
    "fire_station = pd.read_csv('data/firestation.csv') \n",
    "pop = pd.read_csv('data/hap_pop.csv',encoding='cp949') \n",
    "forest_area = gpd.read_file('data/hap_tree.zip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대상지 선정 (공공데이터포털 산불 API 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CGbHIt7kpe1"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(2014, 2024):\n",
    "    key=''\n",
    "    url=f'http://apis.data.go.kr/1400000/forestStusService/getfirestatsservice?serviceKey={key}&'\n",
    "    queryParams =urlencode({quote_plus('pageNo') : '1',quote_plus('numOfRows') : '9999',\n",
    "                            quote_plus('searchStDt') : f'{i}0101',quote_plus('searchEdDt') : f'{i}1231'})\n",
    "\n",
    "    url2=url+queryParams\n",
    "    response = urlopen(url2)\n",
    "    results = response.read().decode(\"utf-8\")\n",
    "    results_to_json = xmltodict.parse(results)\n",
    "    d = json.loads(json.dumps(results_to_json))\n",
    "    data.extend(d['response']['body']['items']['item'])\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "si_do={'강원':'Gangwon-do','경기':'Gyeonggi-do', '경남':'Gyeongsangnam-do','경북':'Gyeongsangbuk-do',\n",
    "       '광주':'Gwangju','대구':'Daegu','대전':'Daejeon','부산':'Busan',\n",
    "       '서울':'Seoul','세종':'Sejongsi','울산':'Ulsan','인천':'Incheon',\n",
    "       '전남':'Jeollanam-do','전북':'Jeollabuk-do','제주':'Jeju-do','충남':'Chungcheongnam-do',\n",
    "       '충북':'Chungcheongbuk-do'}\n",
    "\n",
    "df['eng_region']=df['locsi'].apply(lambda x: si_do[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = df.groupby('locsi').size()\n",
    "df_size = df_size.reset_index()\n",
    "df_size.columns = ['시도', '산불건수']\n",
    "\n",
    "df_sorted = df_size.sort_values(by='산불건수', ascending=False)\n",
    "\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_sorted, x='시도', y='산불건수', palette=[\n",
    "    'red' if x == '경남' else 'gray' for x in df_sorted['시도']\n",
    "])\n",
    "plt.title('전국 시도별 산불 발생 건수 (최근 10년)', fontsize=14)\n",
    "plt.ylabel('건수')\n",
    "plt.xlabel('시도')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gn = df[df['locsi'] == '경남'].reset_index(drop=True)\n",
    "\n",
    "df_gn.dropna(subset=['locgungu'], inplace=True)\n",
    "df_gn['locgungu'] = df_gn['locgungu'].apply(lambda x : '창원' if isinstance(x, str) and '창원' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPfyO6Cdd-YD"
   },
   "outputs": [],
   "source": [
    "fire_freq_area = df_gn.groupby('locgungu').size().reset_index(name='fire_count')\n",
    "\n",
    "df_gn['log_damagearea'] = np.log1p(df_gn['damagearea'])\n",
    "fire_freq_area['total_area'] = fire_freq_area['locgungu'].map(df_gn.groupby('locgungu')['log_damagearea'].sum())\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "fire_freq_area[['fire_count_scaled', 'total_area_scaled']] = scale.fit_transform(fire_freq_area[['fire_count', 'total_area']])\n",
    "fire_freq_area['risk_score'] = fire_freq_area['fire_count_scaled']*0.5 + fire_freq_area['total_area_scaled']*0.5\n",
    "fire_freq_area['risk_score_100'] = fire_freq_area['risk_score']*100\n",
    "\n",
    "# risk score를 이용한 버블차트 >> 최종적으로 합천 선택\n",
    "plt.rc('font', family='Malgun Gothic') \n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=fire_freq_area.sort_values('risk_score'),\n",
    "    x='locgungu',         \n",
    "    y='total_area',         \n",
    "    size='risk_score',      \n",
    "    hue='risk_score',        \n",
    "    sizes=(100,2000),\n",
    "    palette='Reds',\n",
    "    legend=None\n",
    ")\n",
    "\n",
    "plt.title('시군별 산불 빈도와 피해 면적에 따른 시각화', fontsize=16)\n",
    "plt.xlabel('시군', fontsize=12)\n",
    "plt.ylabel('피해 면적', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0jsX965ySx4"
   },
   "outputs": [],
   "source": [
    "df_hapcheon = df_gn[df_gn['locgungu'] == '합천'].reset_index(drop=True)\n",
    "df_hapcheon = df_hapcheon[['startyear','damagearea', 'locmenu']]\n",
    "#df_hapcheon.to_csv('df_hapcheon', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읍면동 중심좌표(경계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공공데이터포털 (통계청_SGIS 행정구역 통계 및 경계) 자료 이용\n",
    "shapefile_path = ''\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# 합천군 코드 : 38600으로 시작\n",
    "hapcheon_gdf = gdf[gdf['ADM_CD'].str.startswith('38600')].copy()\n",
    "hapcheon_gdf.drop('BASE_DATE', axis=1, inplace=True)\n",
    "hapcheon_gdf = hapcheon_gdf.reset_index(drop= True)\n",
    "\n",
    "hapcheon_gdf = hapcheon_gdf.to_crs(epsg=5186)\n",
    "hapcheon_gdf['centroid'] = hapcheon_gdf.geometry.centroid\n",
    "hapcheon_gdf.set_geometry('centroid', inplace=True)\n",
    "\n",
    "# 위도/ 경도로 변환\n",
    "hapcheon_centroid = hapcheon_gdf.to_crs(epsg=4326)\n",
    "hapcheon_centroid['ADM_NM'] = hapcheon_centroid['ADM_NM'].str[:-1] \n",
    "hapcheon_centroid['lon'] = hapcheon_centroid.geometry.x\n",
    "hapcheon_centroid['lat'] = hapcheon_centroid.geometry.y\n",
    "# hapcheon_centroid.to_csv('hapcheon_centroid.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위험도(빈도, 피해 면적) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hap = df_hapcheon.copy()\n",
    "hap_center = hapcheon_centroid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5Zi6FKTf9nT"
   },
   "outputs": [],
   "source": [
    "# 빈도\n",
    "df_hap['freq'] = df_hap['startyear'].apply(lambda x : 0.6 if x >= 2021 else 0.4)\n",
    "year_freq = df_hap.groupby('locmenu')['freq'].sum().reset_index()\n",
    "year_freq.columns = ['ADM_NM', 'year_score']\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "year_freq['year_score_scaled'] = scale.fit_transform(year_freq[['year_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKq03-nAc03_"
   },
   "outputs": [],
   "source": [
    "# 피해면적\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "df_hap['damagearea_scaled'] = np.log1p(df_hap['damagearea'])\n",
    "df_hap['damagearea_scaled'] = scale.fit_transform(df_hap[['damagearea_scaled']])\n",
    "\n",
    "damage_area = df_hap.groupby('locmenu')['damagearea'].sum().reset_index()\n",
    "damage_area.columns = ['ADM_NM', 'damagearea']\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "damage_area['damagearea_scaled'] = np.log1p(damage_area['damagearea'])\n",
    "damage_area['damagearea_scaled'] = scale.fit_transform(damage_area[['damagearea_scaled']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위험도(자연요소) 계산 (기상청API 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j53oowi-nZcO"
   },
   "outputs": [],
   "source": [
    "key = ''\n",
    "wind_url = f'https://apihub.kma.go.kr/api/typ01/url/sts_wind.php?authKey={key}'\n",
    "\n",
    "wind_data = []\n",
    "startyear = 2014\n",
    "endyear = 2023\n",
    "\n",
    "for year in range(startyear, endyear + 1):\n",
    "    for month in range(1, 13):\n",
    "        tm1 = f'{year}{month:02d}'  # 예: 201401\n",
    "        tm2 = f'{year}{month:02d}'  # 예: 201401\n",
    "\n",
    "        # 파라미터 설정\n",
    "        params = {\n",
    "            'tm1': tm1,\n",
    "            'tm2': tm2,\n",
    "            'stn_id': 0,  # 전국 데이터\n",
    "            'disp': 1,\n",
    "            'help': 0\n",
    "        }\n",
    "        response = requests.get(wind_url, params=params)\n",
    "        # StringIO를 이용해 응답 텍스트를 pandas로 읽기\n",
    "        # 응답 데이터가 CSV 형태로 제공된다고 가정하고 StringIO로 읽기\n",
    "        if response.text:\n",
    "            df = pd.read_csv(StringIO(response.text), sep='\\s+')  # CSV 형식으로 읽기\n",
    "            # 데이터에 연도와 월을 추가\n",
    "            df['Year'] = year\n",
    "            df['Month'] = month\n",
    "            wind_data.append(df)  # DataFrame 리스트에 추가\n",
    "        else:\n",
    "            print(f\"Empty data for {year}-{month:02d}\")\n",
    "\n",
    "wind_df = pd.concat(wind_data, ignore_index=True)\n",
    "# wind_df.to_csv('wind_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합천 기상관측소 바람 데이터 불러오기 (대표 관측소)\n",
    "hap_wind = wind_df[(wind_df['STN_ID']==285) & (wind_df['lon'] == 35.56505)].reset_index(drop=True)\n",
    "\n",
    "mean_wsmax = hap_wind[hap_wind.WS_MAX >= hap_wind.WS_MAX.quantile(0.9)]['WS_MAX'].mean() / hap_wind.WS_MAX.quantile(0.95)\n",
    "mean_wsinsmax = hap_wind[hap_wind.WS_INS_MAX >= hap_wind.WS_INS_MAX.quantile(0.9)]['WS_INS_MAX'].mean() / hap_wind.WS_INS_MAX.quantile(0.95)\n",
    "wind_freq = hap_wind[hap_wind.WS_INS_MAX >= hap_wind.WS_INS_MAX.quantile(0.9)].shape[0] / hap_wind.shape[0]\n",
    "\n",
    "# 풍속 위험도 계산\n",
    "wind_risk = 0.35*mean_wsmax + 0.35*mean_wsinsmax + 0.3*wind_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uetrYM5tLkHr"
   },
   "outputs": [],
   "source": [
    "# 나무 종류별 가중치: 침엽수(1)=0.4, 활엽수(2)=0.1, 혼효림(3)=0.15, 대나무(4)=0.35\n",
    "forest_area.drop('geometry', axis=1, inplace = True)\n",
    "forest_area.ADM_NM = forest_area.ADM_NM.str[:-1]\n",
    "forest_area = forest_area[forest_area['fo_area'] != 0].copy()\n",
    "\n",
    "# 단위를 km^2로 통합\n",
    "forest_area['fo_area'] = forest_area['fo_area'] / 1000000\n",
    "\n",
    "hap_forest_area = forest_area.groupby(['ADM_NM','FRTP_CD'])['fo_area'].sum().reset_index()\n",
    "tree_ratio = {1 : 0.4, 2 : 0.1, 3 : 0.15 ,4 : 0.35}\n",
    "hap_forest_area['tree_score'] = hap_forest_area.apply(lambda x: tree_ratio[int(x['FRTP_CD'])] * x['fo_area'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_type_map = {\n",
    "    '1': '침엽수림',\n",
    "    '2': '활엽수림',\n",
    "    '3': '혼효림',\n",
    "    '4': '대나무'\n",
    "}\n",
    "hap_forest_area['tree_type'] = hap_forest_area['FRTP_CD'].map(tree_type_map)\n",
    "\n",
    "# 피벗테이블 변환: 행=ADM_NM, 열=tree_type, 값=fo_area\n",
    "pivot_df = hap_forest_area.pivot_table(index='ADM_NM', columns='tree_type', values='fo_area',aggfunc='sum',).fillna(0)\n",
    "\n",
    "colors = {\n",
    "    '침엽수림': '#2ca02c',\n",
    "    '활엽수림': '#d62728',\n",
    "    '혼효림': '#1f77b4',\n",
    "    '대나무': '#ff7f0e'\n",
    "}\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottom = np.zeros(len(pivot_df))\n",
    "\n",
    "for tree in ['침엽수림', '활엽수림', '혼효림', '대나무']:\n",
    "    ax.bar(pivot_df.index, pivot_df[tree], bottom=bottom, label=tree, color=colors[tree])\n",
    "    bottom += pivot_df[tree]\n",
    "\n",
    "ax.set_ylabel('산림면적 (km²)')\n",
    "ax.set_title('읍면별 나무종류별 산림면적 분포 (스택형 막대그래프)')\n",
    "ax.legend(title='나무종류',fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJVj7RAF_9lw"
   },
   "outputs": [],
   "source": [
    "# 정규화 후 자연 요인 기반 위험도 계산\n",
    "hap_nat_risk = hap_forest_area.groupby('ADM_NM')['tree_score'].sum().reset_index()\n",
    "hap_nat_risk['wind_risk'] = wind_risk\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "hap_nat_risk['tree_score_scaled'] = scale.fit_transform(hap_nat_risk[['tree_score']])\n",
    "hap_nat_risk['nature_risk'] = hap_nat_risk['wind_risk']*0.2 + hap_nat_risk['tree_score_scaled']*0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위험도(중요지역 인접도) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tT12_x2uyhOJ"
   },
   "outputs": [],
   "source": [
    "# 국가유산청 api - 문화재 목록\n",
    "\n",
    "url = 'http://www.khs.go.kr/cha/SearchKindOpenapiList.do'\n",
    "params = {\n",
    "    'ccbaCtcd': '38', # 경남\n",
    "    'pageIndex': 1,\n",
    "    'pageUnit': 100,\n",
    "}\n",
    "\n",
    "all_items = []\n",
    "while True:\n",
    "    response = requests.get(url, params=params)\n",
    "    data_dict = xmltodict.parse(response.content)\n",
    "    items = data_dict['result'].get('item', [])\n",
    "    if not items:\n",
    "        break\n",
    "        \n",
    "    if isinstance(items, dict):  \n",
    "        items = [items]\n",
    "\n",
    "    all_items.extend(items)\n",
    "    params['pageIndex'] += 1\n",
    "\n",
    "culture = pd.DataFrame(all_items)\n",
    "# culture.to_csv('gn_culture.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyF1lopKzTSw"
   },
   "outputs": [],
   "source": [
    "hapcheon_culture = culture[culture['ccsiName'] == '합천군'].reset_index(drop=True)\n",
    "hapcheon_culture = hapcheon_culture[hapcheon_culture['longitude'] != 0]\n",
    "\n",
    "# 화재 피해를 입을 시 사회적, 경제적 파급력이 큰 국보, 보물인 데이터만 추출\n",
    "culture_type = ['국보', '보물']\n",
    "hap_imp_culture = hapcheon_culture[hapcheon_culture['ccmaName'].isin(culture_type)].copy()\n",
    "\n",
    "hap_imp_culture['dup'] = hap_imp_culture['ccbaMnm1'].apply(lambda x : '해인사' if '해인사' in x else(\n",
    "                                                           '영암사지' if '영암사지' in x else(\n",
    "                                                            '청량사' if '청량사' in x else x)))\n",
    "\n",
    "hap_uniq_culture = hap_imp_culture.drop_duplicates(subset=['dup']).reset_index(drop=True)\n",
    "uniq_culture = hap_uniq_culture\n",
    "uniq_culture = hap_uniq_culture[['dup','longitude','latitude']].rename(columns={'dup': 'name', 'longitude': 'lon', 'latitude': 'lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsDv7OmZr4yT"
   },
   "outputs": [],
   "source": [
    "# haversine 라이브러리 사용하여 읍면 중심좌표, 문화재 좌표 직선거리 구하기\n",
    "hap_copy = hapcheon_centroid.copy()\n",
    "culture_result = []\n",
    "\n",
    "for idx, row in hap_copy.iterrows():\n",
    "    hap_xy = (row['lat'], row['lon'])\n",
    "    min_dist = float('inf')\n",
    "    culture_name = None\n",
    "\n",
    "    for cul_idx, cul_row in uniq_culture.iterrows():\n",
    "        cul_xy = (cul_row['lat'], cul_row['lon'])\n",
    "        distance = haversine(hap_xy, cul_xy, unit='km')\n",
    "\n",
    "        if distance < min_dist:\n",
    "            min_dist = distance\n",
    "            culture_name = cul_row['name']\n",
    "\n",
    "    culture_result.append({\n",
    "        'ADM_NM' : row['ADM_NM'],\n",
    "        'culture_name' : culture_name,\n",
    "        'min_dist' : min_dist\n",
    "    })\n",
    "culture_nearest = pd.DataFrame(culture_result)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "culture_nearest['min_dist_scale'] = 1 - scale.fit_transform(culture_nearest[['min_dist']]).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WminkmKyi9NJ"
   },
   "outputs": [],
   "source": [
    "# 합천의 인구, 면적 데이터\n",
    "pop.ADM_NM = pop.ADM_NM.str[:-1]\n",
    "pop['pop_density'] = pop['count'] / pop['area']\n",
    "pop['log_pop_density'] = np.log(pop['pop_density'])\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "pop['pop_scale'] = scale.fit_transform(pop[['log_pop_density']])\n",
    "\n",
    "# 인구밀집도(0.6)와 읍면-문화재 최소거리(0.4)를 합하여 중요지역 인접정도에 대한 위험도 점수 계산\n",
    "culture_nearest = culture_nearest.merge(pop[['ADM_NM','pop_scale']], how = 'left', on = 'ADM_NM')\n",
    "culture_nearest['nearest_risk'] = culture_nearest['pop_scale']*0.6 + culture_nearest['min_dist_scale']*0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp4VeFJ5RMuC"
   },
   "source": [
    "### 위험도(초동대응 어려운 지역) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLJtlKgG19jF"
   },
   "outputs": [],
   "source": [
    "# 각 읍면과 소방서와의 최소 거리\n",
    "def firestation_distance(lat, lon):\n",
    "    # 소방서 좌표 튜플로 변환\n",
    "    fire_station_xy = tuple(zip(fire_station['경도'], fire_station['위도']))\n",
    "    G = ox.graph_from_point((lat, lon), dist=10000, network_type='drive_service')  # 10km 반경, 차도만 고려\n",
    "\n",
    "    # 좌표와 가장가까운 노드 생성\n",
    "    centroid_node = ox.nearest_nodes(G, lon, lat)\n",
    "    firestation_node = [ox.nearest_nodes(G, lon, lat) for lon, lat in fire_station_xy]\n",
    "\n",
    "    dist = []\n",
    "\n",
    "    # 노드가 없어서 거리계산이 안될경우 무한대 처리\n",
    "    for node in firestation_node:\n",
    "        try:\n",
    "            path_length = nx.shortest_path_length(G, source=centroid_node, target=node, weight='length')\n",
    "            dist.append(path_length)\n",
    "\n",
    "        except nx.NetworkXNoPath:\n",
    "            dist.append(float('inf'))\n",
    "\n",
    "    min_distance = min(dist) / 1000  # km단위로 변환\n",
    "\n",
    "    return min_distance\n",
    "\n",
    "\n",
    "# 각 읍면별 인접 도로 개수 (10km 단위)\n",
    "def count_road(lat, lon):\n",
    "    G = ox.graph_from_point((lat, lon), dist=10000, network_type='drive_service')  # 10km 반경, 차도만 고려\n",
    "    if G is None or len(G.edges) == 0:\n",
    "        return 0\n",
    "\n",
    "    # 도로 구간 가져오기 + 중복제거\n",
    "    edge = ox.convert.graph_to_gdfs(G, nodes=False, edges=True).reset_index()\n",
    "    if edge.empty or any(col not in edge.columns for col in ['v', 'key', 'u']):\n",
    "        return 0\n",
    "\n",
    "    # 소방차가 다닐 수 있는 거리만 추출\n",
    "    edge['highway_car'] = edge['highway'].apply(lambda v : [v] if isinstance(v, str) else v)\n",
    "    valid_highways = {'primary', 'secondary', 'tertiary'}\n",
    "    filter_edge = edge[edge['highway_car'].apply(lambda list : all(x in valid_highways for x in list))]\n",
    "\n",
    "    unique_edge = filter_edge.drop_duplicates(subset=['u','key','v'])\n",
    "    edge_count = len(unique_edge)\n",
    "    return edge_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNT8PbIZv5m3"
   },
   "outputs": [],
   "source": [
    "hap_center['min_dist_firestation'] = hap_center.apply(lambda x : firestation_distance(x['lat'], x['lon']), axis = 1)\n",
    "hap_center['road_count'] = hap_center.apply(lambda x : count_road(x['lat'], x['lon']), axis = 1)\n",
    "\n",
    "# 용량이 너무 커서 따로 csv 파일을 저장\n",
    "#hap_center.to_csv('초동대응.csv', index=False)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "hap_center['min_distance_scaled'] = scale.fit_transform(hap_center[['min_dist_firestation']])\n",
    "hap_center['road_count_scaled'] = 1 - scale.fit_transform(hap_center[['road_count']])\n",
    "hap_center['first_response_scaled'] = hap_center['min_distance_scaled']*0.6 + hap_center['road_count_scaled']*0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3QkfbBASR7j"
   },
   "source": [
    "### 최종 위험도 데이터프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfJHF6R8StSz"
   },
   "outputs": [],
   "source": [
    "hap_center = hap_center.merge(year_freq[['ADM_NM', 'year_score_scaled']], on='ADM_NM', how='left')\n",
    "hap_center = hap_center.merge(damage_area[['ADM_NM', 'damagearea_scaled']], on='ADM_NM', how='left')\n",
    "\n",
    "hap_center = hap_center.merge(culture_nearest[['ADM_NM','nearest_risk']], how='left', on='ADM_NM')\n",
    "hap_center = hap_center.merge(hap_nat_risk[['ADM_NM','nature_risk']], how='left', on='ADM_NM')\n",
    "\n",
    "# 빈도, 면적 부분에서 해당 읍면의 화재 데이터가 없어서 Nan 출력\n",
    "hap_center.fillna(0, inplace=True)\n",
    "\n",
    "# 최종위험도\n",
    "hap_center['final_risk'] = (\n",
    "    hap_center['year_score_scaled'] * 0.2 +\n",
    "    hap_center['damagearea_scaled'] * 0.2 +\n",
    "    hap_center['first_response_scaled'] * 0.2 +\n",
    "    hap_center['nearest_risk'] * 0.2 +\n",
    "    hap_center['nature_risk'] * 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3eAXYFkexTJ"
   },
   "source": [
    "### 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtBqHChJ-8Qr"
   },
   "outputs": [],
   "source": [
    "# 합천 중심좌표 정규화\n",
    "scale = MinMaxScaler()\n",
    "hap_center[['lon_scaled', 'lat_scaled']] = scale.fit_transform(hap_center[['lon', 'lat']])\n",
    "\n",
    "# 가중치 설정\n",
    "w_risk = 0.7\n",
    "w_lon = 0.15\n",
    "w_lat = 0.15\n",
    "\n",
    "# 기존 정규화된 컬럼 불러오기\n",
    "lon_scaled = hap_center['lon_scaled'].to_numpy()\n",
    "lat_scaled = hap_center['lat_scaled'].to_numpy()\n",
    "final_risk = hap_center['final_risk'].to_numpy()\n",
    "\n",
    "# 가중치 반영해서 새로운 X_scaled 배열 만들기\n",
    "X_scaled = np.vstack([\n",
    "    w_lon * lon_scaled,\n",
    "    w_lat * lat_scaled,\n",
    "    w_risk * final_risk\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmedoids와 kmeans 실루엣 계수 비교하기\n",
    "\n",
    "silhouette_kmedoids = []\n",
    "silhouette_kmeans = []\n",
    "range_n_clusters = range(2, 11)\n",
    "\n",
    "for k in range_n_clusters:\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=42, method='pam')\n",
    "    kmed_labels = kmedoids.fit_predict(X_scaled)\n",
    "    kmed_score = silhouette_score(X_scaled, kmed_labels)\n",
    "    silhouette_kmedoids.append(kmed_score)\n",
    "\n",
    "for k in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "    kmeans_score = silhouette_score(X_scaled, kmeans_labels)\n",
    "    silhouette_kmeans.append(kmeans_score)\n",
    "\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.plot(range_n_clusters, silhouette_kmedoids, marker='o', color='orange', label = 'KMedoids')\n",
    "plt.plot(range_n_clusters, silhouette_kmeans, marker='o', color='blue', label = 'KMeans')\n",
    "\n",
    "# k = 4 일 때 kmedoids의 실루엣계수가 가장높음\n",
    "k = 4\n",
    "kmed_score_4 = silhouette_kmedoids[k - 2]\n",
    "plt.text(k, kmed_score_4 + 0.01, f'{kmed_score_4:.3f}', color='orange', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.title('Silhouette Score for KMedoids, KMeans')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.legend(loc='upper right',fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedoids  = KMedoids(n_clusters=4, random_state=42, method='pam')  \n",
    "kmedoids.fit(X_scaled)\n",
    "\n",
    "hap_center['cluster'] = kmedoids.labels_\n",
    "cols = ['ADM_NM', 'ADM_CD', 'geometry', 'lon', 'lat', 'final_risk','cluster']\n",
    "hap_center = hap_center[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ijst_X_YeQc"
   },
   "source": [
    "### PuLP를 사용하여 MCLP 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO-ZsQ5QGdxT"
   },
   "outputs": [],
   "source": [
    "# type(hap_center['geometry'].iloc[0])\n",
    "\n",
    "## hap_center['geometry'] = hap_center['geometry'].apply(wkt.loads)\n",
    "# gdf = gpd.GeoDataFrame(hap_center, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "## 최종파일 내보내기\n",
    "# gdf.to_csv('hap_final_risk_kmedoids.csv',index=False)\n",
    "# gdf.to_file('hap_final_risk_kmedoids.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zUfm6bwaeHgF"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/hap_final_risk_kmedoids.csv')\n",
    "df = hap_center.copy()\n",
    "\n",
    "# 후보지 설정\n",
    "idx = df.groupby('cluster')['final_risk'].idxmax()\n",
    "facility_candidates = df.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_points = df.copy()\n",
    "\n",
    "def haversine_matrix(source, target):\n",
    "    # 두 지점 간 거리 계산 (km)\n",
    "    source_rad = np.radians(source[['lat','lon']].to_numpy())\n",
    "    target_rad = np.radians(target[['lat','lon']].to_numpy())\n",
    "    dist_matrix = haversine_distances(source_rad, target_rad) * 6371 \n",
    "    return dist_matrix\n",
    "\n",
    "distance_matrix = haversine_matrix(demand_points, facility_candidates)\n",
    "\n",
    "\n",
    "for r in [7, 10]:\n",
    "    coverage_matrix = (distance_matrix <= r).astype(int)\n",
    "    for p in [3,4,5]:\n",
    "        model = LpProblem('MCLP', LpMaximize)\n",
    "        x_vars = [LpVariable(f'x_{j}', cat=LpBinary) for j in range(len(facility_candidates))]\n",
    "        y_vars = [LpVariable(f'y_{i}', cat=LpBinary) for i in range(len(demand_points))]\n",
    "\n",
    "        # 목적함수 : 위험도 최대화\n",
    "        model += lpSum(demand_points.loc[i, 'final_risk'] * y_vars[i]for i in range(len(demand_points)))\n",
    "\n",
    "        # 제약조건 : 반경 내 커버\n",
    "        for i in range(len(demand_points)):\n",
    "            model += y_vars[i] <= lpSum(coverage_matrix[i,j] * x_vars[j] for j in range(len(facility_candidates)))\n",
    "        model += lpSum(x_vars) <= p\n",
    "\n",
    "        model.solve(PULP_CBC_CMD(msg=0))\n",
    "\n",
    "        # 결과 요약\n",
    "        covered_demands = demand_points[[var.value() == 1 for var in y_vars]].copy()  # 중복 제거\n",
    "        covered_risk_sum = covered_demands.final_risk.sum()\n",
    "        n_selected = sum([var.value() == 1 for var in x_vars])\n",
    "        a_covered = len(covered_demands)\n",
    "        total_risk_sum = demand_points.final_risk.sum()\n",
    "        \n",
    "        coverage_ratio = covered_risk_sum / total_risk_sum if total_risk_sum > 0 else 0\n",
    "        efficiency = covered_risk_sum / n_selected if n_selected > 0 else 0\n",
    "        print(f\"반경: {r} km, 설치개수: {p}, 위험도 커버율: {coverage_ratio:.2%}, 위험도 효율성: {efficiency:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "xPFnN8qx81Aj"
   },
   "outputs": [],
   "source": [
    "# MCLP 최적화 - 반경: 7km, 설치 개수(p): 3개\n",
    "demand_points = df.copy()\n",
    "\n",
    "def haversine_matrix(source, target):\n",
    "    source_rad = np.radians(source[['lat','lon']].to_numpy())\n",
    "    target_rad = np.radians(target[['lat','lon']].to_numpy())\n",
    "    dist_matrix = haversine_distances(source_rad, target_rad) *  6371 # 지구 반지름\n",
    "    return dist_matrix\n",
    "\n",
    "distance_matrix = haversine_matrix(demand_points, facility_candidates)\n",
    "\n",
    "# 커버리지 매트릭스 (거리 <= 7km)\n",
    "coverage_matrix = (distance_matrix <= 7).astype(int)\n",
    "p = 3\n",
    "\n",
    "# MCLP 모델\n",
    "model = LpProblem('MCLP', LpMaximize)\n",
    "\n",
    "x_vars = [LpVariable(f'x_{j}', cat=LpBinary) for j in range(len(facility_candidates))]\n",
    "y_vars = [LpVariable(f'y_{i}', cat=LpBinary) for i in range(len(demand_points))]\n",
    "\n",
    "# 목적함수\n",
    "model += lpSum(demand_points.loc[i, 'final_risk'] * y_vars[i]for i in range(len(demand_points)))\n",
    "\n",
    "# 제약조건\n",
    "for i in range(len(demand_points)):\n",
    "    model += y_vars[i] <= lpSum(coverage_matrix[i,j] * x_vars[j] for j in range(len(facility_candidates)))\n",
    "model += lpSum(x_vars) <= p\n",
    "\n",
    "# 모델 최적화\n",
    "model.solve(PULP_CBC_CMD(msg=0))\n",
    "\n",
    "# 최적 선택 후보지 및 커버된 수요지점 추출\n",
    "selected_facilities = facility_candidates[[var.value()==1 for var in x_vars]].copy()\n",
    "covered_demands = demand_points[[var.value() == 1 for var in y_vars]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSqhpdSiQz1h"
   },
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_hap = gpd.read_file('data/hap_final_risk_kmedoids.zip')\n",
    "\n",
    "# (위상 오류 방지)\n",
    "final_hap['geometry'] = final_hap['geometry'].buffer(0)\n",
    "\n",
    "#좌표계 재설정 \n",
    "final_hap.set_crs(epsg=5186, inplace=True, allow_override=True)  \n",
    "final_hap = final_hap.to_crs(epsg=4326)  # folium, matplotlib에서 사용 가능하도록 위경도 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위험도 시각화\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic') \n",
    "fig, ax = plt.subplots(figsize=(7, 10))\n",
    "\n",
    "final_hap.plot(\n",
    "    column='final_risk',          \n",
    "    cmap='OrRd',                 \n",
    "    linewidth=0.8,                \n",
    "    edgecolor='black',          \n",
    "    legend=True,                 \n",
    "    legend_kwds={'label': \"최종 위험도\", 'shrink': 0.6},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# 읍면 이름 라벨 표시\n",
    "for idx, row in final_hap.iterrows():\n",
    "    plt.annotate(\n",
    "        text=row['ADM_NM'],\n",
    "        xy=(row['lon'], row['lat']),\n",
    "        horizontalalignment='center',\n",
    "        fontsize=8,\n",
    "        color='black'\n",
    "    )\n",
    "\n",
    "ax.set_title('합천군 읍면별 산불 위험도', fontsize=14)\n",
    "ax.axis('off') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터링 시각화\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic') \n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# 클러스터 컬럼을 기준으로 시각화\n",
    "final_hap.plot(column='cluster', categorical=True, legend=True, cmap='tab20', edgecolor='black', ax=ax)\n",
    "\n",
    "# 읍면 이름 추가: 각 폴리곤의 중심 좌표에 이름을 표시\n",
    "for idx, row in final_hap.iterrows():\n",
    "    centroid = row['geometry'].centroid\n",
    "    ax.text(centroid.x, centroid.y, row['ADM_NM'], fontsize=9, ha='center', color='black', fontweight='bold')\n",
    "\n",
    "plt.title(\"합천군 읍면별 클러스터링 결과\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mclp 결과 시각\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic') \n",
    "\n",
    "# 10km 반경 원 그리기 함수 (위경도 기준 근사)\n",
    "def plot_circle(ax, lon, lat, radius_km, **kwargs):\n",
    "    earth_radius = 6371  # km\n",
    "    radius_deg = radius_km / earth_radius * (180 / np.pi)\n",
    "    circle = plt.Circle((lon, lat), radius_deg, **kwargs)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "final_hap.plot(column='final_risk', cmap='YlOrRd', legend=True,\n",
    "               legend_kwds={'label': \"위험도 (final_risk)\", 'shrink': 0.6},\n",
    "               edgecolor='black', linewidth=0.5, ax=ax, alpha=0.7)\n",
    "\n",
    "# 설치 후보지 마커 (*)\n",
    "ax.scatter(selected_gdf['lon'], selected_gdf['lat'],\n",
    "           color='blue', marker='o', s=50, label='설치 후보지')\n",
    "\n",
    "# 설치 후보지, 커버 수요지역 라벨 추가\n",
    "for idx, row in selected_gdf.iterrows():\n",
    "    ax.text(row['lon'] + 0.005, row['lat'] + 0.005,\n",
    "            row['ADM_NM'], fontsize=10, fontweight='bold', color='blue')\n",
    "\n",
    "# 각 설치지점에서 10km 원 표시\n",
    "for idx, row in selected_gdf.iterrows():\n",
    "    plot_circle(ax, row['lon'], row['lat'], 10,\n",
    "                edgecolor='blue', facecolor='none', linestyle='--', linewidth=1.2, alpha=0.3)\n",
    "\n",
    "ax.set_title(\"합천 MCLP 설치 후보지 및 위험도 시각화\", fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T07qJrpzRGa"
   },
   "source": [
    "중심좌표는 단지 모델의 기준점일 뿐,\n",
    "\n",
    "실제 설치에는 지형, 접근성, 토지 이용 가능성, 도로망, 수계 등 여러 요인이 고려되어야함."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wmtEP5tYebGk",
    "9MEmBwuCvcH1"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
